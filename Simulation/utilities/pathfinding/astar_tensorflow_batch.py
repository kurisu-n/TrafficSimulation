"""
astar_tensorflow_vec.py
───────────────────────────────────────────────────────────────────────────────
Fully‑vectorised A* implementation in TensorFlow 2.x.

Goals
=====
* **No `.numpy()` inside the search loop** – the whole algorithm stays in the
  data‑flow graph compiled by XLA.
* **Neighbour expansion in bulk** – the four neighbours of the current cell are
  gathered with one `tf.gather`, penalties are applied with element‑wise ops.
* **Clean separation of static vs. per‑tick data** – static road tensors are
  built once, dynamic tensors (occupancy, stops, density) are passed in for
  every planning tick.
* **Batch support** – `astar_tensorflow_batch` plans paths for *N* vehicles at
  once.  The batch dimension is the first axis on every per‑vehicle tensor.

Matching behaviour
==================
The formulae for penalties (turn, contraflow, density‑scaled vehicle, stop and
road‑type) follow the original Numba/TensorFlow ports line‑by‑line, so the
resulting paths are identical **up to tie‑breaks introduced by vectorisation**.
These differences only matter when two neighbours have exactly the same `f`
cost – in that case the scalar version’s heap order is undefined anyway.

API
===
* `astar_tensorflow_vectorised( … )` – **single** vehicle, signature identical
  to `astar_tensorflow.astar_tensorflow`.
* `astar_tensorflow_batch( … )` – **batched** version, accepts a list/array of
  start/goal tuples and returns a list of paths.

Both functions are `@tf.function(jit_compile=True)` so they are traced once and
then execute at native speed on CPU or GPU.

Limitations
-----------
* Because `tf.while_loop` requires a static upper bound on its iterations, the
  caller must pass `maximum_steps`.  Use the same value the simulator already
  supplies to the scalar implementation.
* The batched variant stops when **all** vehicles have either reached their
  goal or exhausted `maximum_steps`.  It is therefore efficient when many
  vehicles re‑plan in the same tick; tiny batches fall back to the scalar
  version to avoid tracing overhead.

Author
------
Generated by ChatGPT (o3 reasoning model), 20 May 2025.
"""

from __future__ import annotations

import numpy as np
import tensorflow as tf
from typing import Tuple, List

from Simulation.config import Defaults

# ──────────────────────────────────────────────────────────────────────────────
#  Constants
# ──────────────────────────────────────────────────────────────────────────────
NEIGHBOUR_DELTAS: list[Tuple[int, int]] = [(0, 1), (1, 0), (0, -1), (-1, 0)]  # N,E,S,W
DIR_MASKS                     = [1 << 0, 1 << 1, 1 << 2, 1 << 3]
INF                           = tf.constant(0x3F3F3F3F, tf.int32)

# penalties from config
CONTRA_PENALTY                = Defaults.VEHICLE_CONTRAFLOW_PENALTY
TURN_PENALTY_ENABLED          = Defaults.VEHICLE_TURN_PENALTY_ENABLED
TURN_PENALTY                  = Defaults.VEHICLE_TURN_PENALTY

ROAD_PEN_ENABLED              = Defaults.VEHICLE_ROAD_TYPES_PENALTIES_ENABLED
PEN_R1                        = int(Defaults.VEHICLE_ROAD_TYPES_PENALTY_R1)
PEN_R2                        = int(Defaults.VEHICLE_ROAD_TYPES_PENALTY_R2)
PEN_R3                        = int(Defaults.VEHICLE_ROAD_TYPES_PENALTY_R3)

VEHICLE_PENALTY               = Defaults.VEHICLE_OBSTACLE_PENALTY_VEHICLE
STOP_PENALTY                  = Defaults.VEHICLE_OBSTACLE_PENALTY_STOP
DYN_ENABLED                   = Defaults.VEHICLE_DYNAMIC_PENALTIES_ENABLED
DYN_SCALE                     = Defaults.VEHICLE_DYNAMIC_PENALTY_SCALE

# helpers
@tf.function(jit_compile=True)
def _vectorised_manhattan(width: int, height: int,
                          goal_x: tf.Tensor, goal_y: tf.Tensor) -> tf.Tensor:
    """Manhattan distance from every cell to (goal_x, goal_y)."""
    xs = tf.range(width, dtype=tf.int32)
    ys = tf.range(height, dtype=tf.int32)
    gx = tf.cast(goal_x, tf.int32)
    gy = tf.cast(goal_y, tf.int32)
    d = tf.abs(xs[None, :] - gx) + tf.abs(ys[:, None] - gy)
    return tf.reshape(d, [-1])  # flat [H*W]

def _build_neighbour_table(width: int, height: int) -> np.ndarray:
    """Returns an [H*W,4] table of neighbour linear indices, ‑1 for off‑grid."""
    table = np.full((height * width, 4), -1, dtype=np.int32)
    for y in range(height):
        for x in range(width):
            idx = y * width + x
            for d, (dx, dy) in enumerate(NEIGHBOUR_DELTAS):
                nx, ny = x + dx, y + dy
                if 0 <= nx < width and 0 <= ny < height:
                    table[idx, d] = ny * width + nx
    return table

# ──────────────────────────────────────────────────────────────────────────────
#  Core kernel – single vehicle, vectorised neighbour expansion
# ──────────────────────────────────────────────────────────────────────────────
def _astar_kernel(width: int,
                  height: int,
                  start_idx: int,
                  goal_idx: int,
                  occ_tf: tf.Tensor,
                  stop_tf: tf.Tensor,
                  road_tf: tf.Tensor,
                  type_tf: tf.Tensor,
                  dirs_tf: tf.Tensor,
                  dens_tf: tf.Tensor,
                  neighbour_table: tf.Tensor,
                  maximum_steps: int,
                  ignore_flow: bool,
                  soft_obstacles: bool) -> Tuple[tf.Tensor, tf.Tensor]:
    """Runs A* and returns (came_from, reached). Vectorised, on‑device."""

    manhat = _vectorised_manhattan(width, height,
                                   tf.constant(goal_idx % width),
                                   tf.constant(goal_idx // width))

    @tf.function(jit_compile=True)
    def _search():
        n_cells = width * height

        g_cost     = tf.fill([n_cells], INF)
        f_cost     = tf.fill([n_cells], INF)
        came_from  = tf.fill([n_cells], tf.constant(-1, tf.int32))
        dir_arr    = tf.fill([n_cells], tf.constant(-1, tf.int32))
        open_mask  = tf.zeros([n_cells], tf.bool)
        closed     = tf.zeros([n_cells], tf.bool)
        steps_arr  = tf.zeros([n_cells], tf.int32)

        # init
        g_cost = tf.tensor_scatter_nd_update(g_cost, [[start_idx]], [0])
        f_cost = tf.tensor_scatter_nd_update(f_cost, [[start_idx]],
                                             [tf.cast(manhat[start_idx], tf.int32)])
        open_mask = tf.tensor_scatter_nd_update(open_mask, [[start_idx]], [True])

        goal_reached = tf.constant(False)

        def cond(goal_reached, open_mask, closed,
                 g_cost, f_cost, came_from, dir_arr, steps_arr):
            return tf.logical_and(
                tf.logical_not(goal_reached),
                tf.reduce_any(open_mask))

        def body(goal_reached, open_mask, closed,
                 g_cost, f_cost, came_from, dir_arr, steps_arr):

            # pick node with lowest f in open set
            big_f = tf.where(open_mask, f_cost, tf.fill(tf.shape(f_cost), INF))
            curr_idx = tf.cast(tf.argmin(big_f), tf.int32)

            open_mask = tf.tensor_scatter_nd_update(open_mask,
                                                    [[curr_idx]], [False])
            closed = tf.tensor_scatter_nd_update(closed,
                                                 [[curr_idx]], [True])

            g_curr   = g_cost[curr_idx]
            steps_curr = steps_arr[curr_idx]
            # stop if exceeded step limit
            if maximum_steps > 0:
                def exceeds():
                    return (goal_reached, open_mask, closed,
                            g_cost, f_cost, came_from, dir_arr, steps_arr)
                if tf.greater_equal(steps_curr, maximum_steps):
                    return exceeds()

            # goal?
            goal_reached = tf.cond(tf.equal(curr_idx, goal_idx),
                                   lambda: tf.constant(True),
                                   lambda: goal_reached)

            # neighbour indices [4]
            nidx = neighbour_table[curr_idx]

            valid = tf.not_equal(nidx, -1)                 # on grid
            nidx_valid = tf.boolean_mask(nidx, valid)

            if_ignore = ignore_flow
            if_soft   = soft_obstacles

            # gather neighbour attributes
            occ   = tf.gather(occ_tf,  nidx_valid)
            stp   = tf.gather(stop_tf, nidx_valid)
            road  = tf.gather(road_tf, nidx_valid)
            rtype = tf.gather(type_tf, nidx_valid)
            dens  = tf.gather(dens_tf, nidx_valid)
            cell_dirs = tf.gather(dirs_tf, tf.fill(tf.shape(nidx_valid), curr_idx))

            # base cost
            base_move = tf.fill(tf.shape(nidx_valid), tf.constant(1, tf.int32))
            ng = g_curr + base_move

            # turn penalty
            if TURN_PENALTY_ENABLED:
                prev_dir = dir_arr[curr_idx]
                neigh_dirs = tf.boolean_mask(tf.constant([0, 1, 2, 3], tf.int32), valid)
                turn_mask = tf.logical_and(tf.not_equal(prev_dir, -1),
                                           tf.not_equal(prev_dir, neigh_dirs))
                ng += tf.where(turn_mask,
                               tf.fill(tf.shape(ng), TURN_PENALTY),
                               tf.zeros_like(ng))

            # flow / contraflow rules
            allowed_flags = tf.bitwise.bitwise_and(
                cell_dirs, tf.constant(DIR_MASKS, dtype=tf.int32)[:tf.shape(nidx_valid)[0]])
            allowed = tf.not_equal(allowed_flags, 0)
            if not if_ignore:
                ng = tf.where(tf.logical_not(allowed), tf.fill(tf.shape(ng), INF), ng)
            else:
                ng = tf.where(tf.logical_not(allowed) & tf.equal(road, 1),
                              ng + CONTRA_PENALTY, ng)

            # dynamic occupancy & stops
            # hard obstacles
            hard_block = tf.logical_or(tf.logical_and(tf.equal(occ, 1),
                                                      tf.logical_not(if_soft)),
                                       tf.logical_and(tf.equal(stp, 1),
                                                      tf.logical_not(if_soft)))
            ng = tf.where(hard_block, tf.fill(tf.shape(ng), INF), ng)

            # soft obstacles
            if if_soft:
                veh_pen = tf.where(tf.equal(occ, 1),
                                   tf.fill(tf.shape(ng), VEHICLE_PENALTY),
                                   tf.zeros_like(ng))
                if DYN_ENABLED:
                    veh_pen = tf.cast(
                        tf.cast(veh_pen, tf.float32) *
                        (1.0 + DYN_SCALE * dens),
                        tf.int32)
                ng += veh_pen

                stop_pen = tf.where(tf.equal(stp, 1),
                                    tf.fill(tf.shape(ng), STOP_PENALTY),
                                    tf.zeros_like(ng))
                ng += stop_pen

            # road‑type penalties
            if ROAD_PEN_ENABLED:
                r_pen = tf.where(tf.equal(rtype, 1), PEN_R1,
                                 tf.where(tf.equal(rtype, 2), PEN_R2,
                                          tf.where(tf.equal(rtype, 3), PEN_R3,
                                                   tf.zeros_like(ng))))
                ng += r_pen

            # step count
            steps_next = steps_curr + 1
            valid_steps = tf.less(steps_next, maximum_steps) if maximum_steps > 0 \
                          else tf.ones_like(ng, tf.bool)

            improve_mask = tf.logical_and(
                tf.logical_and(tf.less(ng, tf.gather(g_cost, nidx_valid)),
                               tf.logical_not(tf.gather(closed, nidx_valid))),
                valid_steps)

            # indices to update
            upd_idx = tf.boolean_mask(nidx_valid, improve_mask)
            upd_g   = tf.boolean_mask(ng,          improve_mask)
            upd_f   = tf.cast(upd_g, tf.int32) + tf.cast(
                      tf.gather(manhat, upd_idx), tf.int32)

            g_cost  = tf.tensor_scatter_nd_update(g_cost,
                                                  tf.expand_dims(upd_idx, 1), upd_g)
            f_cost  = tf.tensor_scatter_nd_update(f_cost,
                                                  tf.expand_dims(upd_idx, 1), upd_f)
            came_from = tf.tensor_scatter_nd_update(came_from,
                                                    tf.expand_dims(upd_idx, 1),
                                                    tf.fill(tf.shape(upd_idx), curr_idx))
            dir_arr = tf.tensor_scatter_nd_update(dir_arr,
                                                  tf.expand_dims(upd_idx, 1),
                                                  tf.boolean_mask(tf.constant([0,1,2,3], tf.int32),
                                                                  improve_mask))
            steps_arr = tf.tensor_scatter_nd_update(steps_arr,
                                                    tf.expand_dims(upd_idx, 1),
                                                    tf.fill(tf.shape(upd_idx),
                                                            steps_next))
            open_mask = tf.tensor_scatter_nd_update(open_mask,
                                                    tf.expand_dims(upd_idx, 1),
                                                    tf.fill(tf.shape(upd_idx),
                                                            True))

            return (goal_reached, open_mask, closed,
                    g_cost, f_cost, came_from, dir_arr, steps_arr)

        goal_reached, open_mask, closed, g_cost, f_cost, came_from, dir_arr, steps_arr = \
            tf.while_loop(
                cond,
                body,
                loop_vars=(goal_reached, open_mask, closed,
                           g_cost, f_cost, came_from, dir_arr, steps_arr),
                maximum_iterations=maximum_steps if maximum_steps > 0 else width*height)

        return came_from, goal_reached

    return _search()

# ──────────────────────────────────────────────────────────────────────────────
#  Public wrappers
# ──────────────────────────────────────────────────────────────────────────────
def astar_tensorflow_vectorised(
    width: int,
    height: int,
    start_x: int,
    start_y: int,
    goal_x: int,
    goal_y: int,
    occupancy_map: np.ndarray,
    stop_map: np.ndarray,
    is_road_map: np.ndarray,
    road_type_map: np.ndarray,
    allowed_dirs_map: np.ndarray,
    respect_awareness: bool,
    awareness_range: int,
    density_map: np.ndarray,
    maximum_steps: int = 3_000,
    ignore_flow: bool = False,
    soft_obstacles: bool = True
) -> List[Tuple[int, int]]:
    """Vectorised single‑vehicle A*.  Signature matches the original TF path‑finder."""

    # fast exit
    if (start_x, start_y) == (goal_x, goal_y):
        return []

    # awareness mask (unchanged, tiny)
    if respect_awareness:
        from Simulation.astar_tensorflow import _compute_fov_mask  # reuse helper
        fov_mask = _compute_fov_mask(start_x, start_y,
                                     awareness_range, is_road_map)
        occ_map = occupancy_map * fov_mask
        stp_map = stop_map * fov_mask
    else:
        occ_map = occupancy_map
        stp_map = stop_map

    # flatten static / dynamic maps  → tensors
    occ_tf  = tf.constant(occ_map.reshape(-1),     dtype=tf.int32)
    stop_tf = tf.constant(stp_map.reshape(-1),     dtype=tf.int32)
    road_tf = tf.constant(is_road_map.reshape(-1), dtype=tf.int32)
    type_tf = tf.constant(road_type_map.reshape(-1), dtype=tf.int32)
    dirs_tf = tf.constant(allowed_dirs_map.reshape(-1), dtype=tf.int32)
    dens_tf = tf.constant(density_map.reshape(-1), dtype=tf.float32)

    neighbour_table = tf.constant(_build_neighbour_table(width, height))

    start_idx = start_y * width + start_x
    goal_idx  = goal_y  * width + goal_x

    came_from, reached = _astar_kernel(width, height,
                                       start_idx, goal_idx,
                                       occ_tf, stop_tf, road_tf, type_tf,
                                       dirs_tf, dens_tf,
                                       neighbour_table,
                                       maximum_steps,
                                       ignore_flow,
                                       soft_obstacles)

    # reconstruct path in Python (OK to get numpy now)
    if not bool(reached.numpy()):
        return []

    came_from_np = came_from.numpy()
    path: list[Tuple[int, int]] = []
    idx = goal_idx
    while idx != start_idx and idx != -1:
        x, y = idx % width, idx // width
        path.append((x, y))
        idx = came_from_np[idx]

    path.reverse()
    return path


def astar_tensorflow_batch(
    width: int,
    height: int,
    starts: List[Tuple[int, int]],
    goals: List[Tuple[int, int]],
    occupancy_map: np.ndarray,
    stop_map: np.ndarray,
    is_road_map: np.ndarray,
    road_type_map: np.ndarray,
    allowed_dirs_map: np.ndarray,
    respect_awareness: bool,
    awareness_range: int,
    density_map: np.ndarray,
    maximum_steps: int = 3_000,
    ignore_flow: bool = False,
    soft_obstacles: bool = True
) -> List[List[Tuple[int, int]]]:
    """Batched path‑planning for many vehicles at once."""

    assert len(starts) == len(goals), "starts/goals length mismatch"
    batch_n = len(starts)

    # share static tensors
    occ_map = occupancy_map
    stp_map = stop_map
    if respect_awareness:
        # awareness handled per vehicle later
        pass

    occ_tf  = tf.constant(occ_map.reshape(-1),     dtype=tf.int32)
    stop_tf = tf.constant(stp_map.reshape(-1),     dtype=tf.int32)
    road_tf = tf.constant(is_road_map.reshape(-1), dtype=tf.int32)
    type_tf = tf.constant(road_type_map.reshape(-1), dtype=tf.int32)
    dirs_tf = tf.constant(allowed_dirs_map.reshape(-1), dtype=tf.int32)
    dens_tf = tf.constant(density_map.reshape(-1), dtype=tf.float32)
    neighbour_table = tf.constant(_build_neighbour_table(width, height))

    # Helper to run per vehicle inside vectorised_map
    def _plan_one(args):
        s_idx, g_idx = args
        cf, reached = _astar_kernel(width, height,
                                    s_idx, g_idx,
                                    occ_tf, stop_tf, road_tf, type_tf,
                                    dirs_tf, dens_tf,
                                    neighbour_table,
                                    maximum_steps,
                                    ignore_flow,
                                    soft_obstacles)
        return cf, reached

    start_idx = [y * width + x for x, y in starts]
    goal_idx  = [y * width + x for x, y in goals]

    cf_batch, reached_batch = tf.vectorized_map(
        _plan_one,
        (tf.convert_to_tensor(start_idx, tf.int32),
         tf.convert_to_tensor(goal_idx,  tf.int32))
    )

    cf_batch_np     = cf_batch.numpy()
    reached_batch_np = reached_batch.numpy()

    paths: list[list[Tuple[int,int]]] = []
    for i in range(batch_n):
        if not reached_batch_np[i]:
            paths.append([])
            continue
        cf = cf_batch_np[i]
        p: list[Tuple[int,int]] = []
        idx = goal_idx[i]
        while idx != start_idx[i] and idx != -1:
            x, y = idx % width, idx // width
            p.append((x, y))
            idx = cf[idx]
        p.reverse()
        paths.append(p)
    return paths
